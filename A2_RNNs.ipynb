{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FZ7Xx__nJmj7"
      },
      "source": [
        "<div style=\"text-align: right\">   </div>\n",
        "\n",
        "\n",
        "Introduction to Deep Learning (2023) &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;| &nbsp;\n",
        "-------|-------------------\n",
        "**Assignment 2 - Recurrent Neural Networks** | <img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/b/b0/UniversiteitLeidenLogo.svg/1280px-UniversiteitLeidenLogo.svg.png\" width=\"300\">\n",
        "\n",
        "\n",
        "\n",
        "# Introduction\n",
        "\n",
        "\n",
        "The goal of this assignment is to learn how to use encoder-decoder recurrent neural networks (RNNs). Specifically we will be dealing with a sequence to sequence problem and try to build recurrent models that can learn the principles behind simple arithmetic operations (**integer addition, subtraction and multiplication.**).\n",
        "\n",
        "<img src=\"https://i.ibb.co/5Ky5pbk/Screenshot-2023-11-10-at-07-51-21.png\" alt=\"Screenshot-2023-11-10-at-07-51-21\" border=\"0\" width=\"500\"></a>\n",
        "\n",
        "In this assignment you will be working with three different kinds of models, based on input/output data modalities:\n",
        "1. **Text-to-text**: given a text query containing two integers and an operand between them (+ or -) the model's output should be a sequence of integers that match the actual arithmetic result of this operation\n",
        "2. **Image-to-text**: same as above, except the query is specified as a sequence of images containing individual digits and an operand.\n",
        "3. **Text-to-image**: the query is specified in text format as in the text-to-text model, however the model's output should be a sequence of images corresponding to the correct result.\n",
        "\n",
        "\n",
        "### Description**\n",
        "Let us suppose that we want to develop a neural network that learns how to add or subtract\n",
        "two integers that are at most two digits long. For example, given input strings of 5 characters: ‘81+24’ or\n",
        "’41-89’ that consist of 2 two-digit long integers and an operand between them, the network should return a\n",
        "sequence of 3 characters: ‘105 ’ or ’-48 ’ that represent the result of their respective queries. Additionally,\n",
        "we want to build a model that generalizes well - if the network can extract the underlying principles behind\n",
        "the ’+’ and ’-’ operands and associated operations, it should not need too many training examples to generate\n",
        "valid answers to unseen queries. To represent such queries we need 13 unique characters: 10 for digits (0-9),\n",
        "2 for the ’+’ and ’-’ operands and one for whitespaces ’ ’ used as padding.\n",
        "The example above describes a text-to-text sequence mapping scenario. However, we can also use different\n",
        "modalities of data to represent our queries or answers. For that purpose, the MNIST handwritten digit\n",
        "dataset is going to be used again, however in a slightly different format. The functions below will be used to create our datasets.\n",
        "\n",
        "---\n",
        "\n",
        "*To work on this notebook you should create a copy of it.*\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sP__1utGJmj_"
      },
      "source": [
        "# Function definitions for creating the datasets\n",
        "\n",
        "First we need to create our datasets that are going to be used for training our models.\n",
        "\n",
        "In order to create image queries of simple arithmetic operations such as '15+13' or '42-10' we need to create images of '+' and '-' signs using ***open-cv*** library. We will use these operand signs together with the MNIST dataset to represent the digits."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "w3nzYbXOJmj8"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'tensorflow'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[1;32mc:\\Users\\ayush\\Downloads\\A2\\A2_RNNs.ipynb Cell 3\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/ayush/Downloads/A2/A2_RNNs.ipynb#W2sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mtf\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/ayush/Downloads/A2/A2_RNNs.ipynb#W2sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m \u001b[39mimport\u001b[39;00m layers, models, optimizers\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/ayush/Downloads/A2/A2_RNNs.ipynb#W2sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpyplot\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mplt\u001b[39;00m\n",
            "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from keras import layers, models, optimizers\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import numpy as np\n",
        "import random\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "from sklearn.utils import shuffle\n",
        "from keras.layers import Dense, LSTM, TimeDistributed, RepeatVector, Dropout\n",
        "# from keras.layers import RNN, Flatten, LSTMCell, SimpleRNN, GRU, Reshape, ConvLSTM2D, Conv2DTranspose, Conv2D, MaxPooling2D\n",
        "# from keras.models import Sequential, load_model\n",
        "from keras.optimizers import Adam\n",
        "from keras.utils import plot_model, to_categorical\n",
        "from keras.callbacks import EarlyStopping, ReduceLROnPlateau, TensorBoard\n",
        "import datetime\n",
        "\n",
        "\n",
        "# Set seeds for reproducibility\n",
        "random_seed = 42\n",
        "random.seed(random_seed)\n",
        "np.random.seed(random_seed)\n",
        "tf.random.set_seed(random_seed)\n",
        "\n",
        "# flags below should be set to run only a subset of the notebook\n",
        "# addition and substraction in 3 flavors\n",
        "run_text2text_53 = True\n",
        "run_image2text_53 = True\n",
        "run_text2image_53 = True\n",
        "# multiplication\n",
        "run_text2text_54 = True\n",
        "run_image2text_54 = True \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 365
        },
        "id": "Z7RGPMxLJmkA",
        "outputId": "a6cf8be6-c32f-40b2-b8ae-517056fba1c8"
      },
      "outputs": [],
      "source": [
        "from scipy.ndimage import rotate\n",
        "# Create plus/minus operand signs\n",
        "def generate_images(number_of_images=50, sign='-'):\n",
        "\n",
        "    blank_images = np.zeros([number_of_images, 28, 28])  # Dimensionality matches the size of MNIST images (28x28)\n",
        "    x = np.random.randint(12, 16, (number_of_images, 2)) # Randomized x coordinates\n",
        "    y1 = np.random.randint(6, 10, number_of_images)       # Randomized y coordinates\n",
        "    y2 = np.random.randint(18, 22, number_of_images)     # -||-\n",
        "\n",
        "    for i in range(number_of_images): # Generate n different images\n",
        "        cv2.line(blank_images[i], (y1[i], x[i,0]), (y2[i], x[i, 1]), (255,0,0), 2, cv2.LINE_AA)     # Draw lines with randomized coordinates\n",
        "        if sign == '+':\n",
        "            cv2.line(blank_images[i], (x[i,0], y1[i]), (x[i, 1], y2[i]), (255,0,0), 2, cv2.LINE_AA) # Draw lines with randomized coordinates\n",
        "        if sign == '*':\n",
        "            cv2.line(blank_images[i], (x[i,0], y1[i]), (x[i, 1], y2[i]), (255,0,0), 2, cv2.LINE_AA)\n",
        "            # Rotate 45 degrees\n",
        "            blank_images[i] = rotate(blank_images[i], -50, reshape=False)\n",
        "            cv2.line(blank_images[i], (x[i,0], y1[i]), (x[i, 1], y2[i]), (255,0,0), 2, cv2.LINE_AA)\n",
        "            blank_images[i] = rotate(blank_images[i], -50, reshape=False)\n",
        "            cv2.line(blank_images[i], (x[i,0], y1[i]), (x[i, 1], y2[i]), (255,0,0), 2, cv2.LINE_AA)\n",
        "\n",
        "    return blank_images\n",
        "\n",
        "def show_generated(images, n=5):\n",
        "    plt.figure(figsize=(2, 2))\n",
        "    for i in range(n**2):\n",
        "        plt.subplot(n, n, i+1)\n",
        "        plt.axis('off')\n",
        "        plt.imshow(images[i])\n",
        "    plt.show()\n",
        "\n",
        "show_generated(generate_images())\n",
        "show_generated(generate_images(sign='+'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lx-Pt6ypJmkD"
      },
      "outputs": [],
      "source": [
        "# Illustrate the generated query/answer pairs\n",
        "unique_characters = '0123456789+- '       # All unique characters that are used in the queries (13 in total: digits 0-9, 2 operands [+, -], and a space character ' '.)\n",
        "highest_integer = 99                      # Highest value of integers contained in the queries\n",
        "\n",
        "max_int_length = len(str(highest_integer))# Maximum number of characters in an integer\n",
        "max_query_length = max_int_length * 2 + 1 # Maximum length of the query string (consists of two integers and an operand [e.g. '22+10'])\n",
        "max_answer_length = 3    # Maximum length of the answer string (the longest resulting query string is ' 1-99'='-98')\n",
        "\n",
        "# Create the data (might take around a minute)\n",
        "(MNIST_data, MNIST_labels), _ = tf.keras.datasets.mnist.load_data()\n",
        "\n",
        "\n",
        "def create_data(unique_characters, highest_integer, num_addends=2, operands=['+', '-']):\n",
        "    \"\"\"\n",
        "    Creates the following data for all pairs of integers up to [1:highest integer][+/-][1:highest_integer]:\n",
        "\n",
        "    @return:\n",
        "    X_text: '51+21' -> text query of an arithmetic operation (5)\n",
        "    X_img : Stack of MNIST images corresponding to the query (5 x 28 x 28) -> sequence of 5 images of size 28x28\n",
        "    y_text: '72' -> answer of the arithmetic text query\n",
        "    y_img :  Stack of MNIST images corresponding to the answer (3 x 28 x 28)\n",
        "\n",
        "    Images for digits are picked randomly from the whole MNIST dataset.\n",
        "    \"\"\"\n",
        "\n",
        "    num_indices = [np.where(MNIST_labels==x) for x in range(10)]\n",
        "    num_data = [MNIST_data[inds] for inds in num_indices]\n",
        "    image_mapping = dict(zip(unique_characters[:10], num_data))\n",
        "    image_mapping['-'] = generate_images()\n",
        "    image_mapping['+'] = generate_images(sign='+')\n",
        "    image_mapping['*'] = generate_images(sign='*')\n",
        "    image_mapping[' '] = np.zeros([1, 28, 28])\n",
        "\n",
        "    X_text, X_img, y_text, y_img = [], [], [], []\n",
        "\n",
        "    for i in range(highest_integer + 1):      # First addend\n",
        "        for j in range(highest_integer + 1):  # Second addend\n",
        "            for sign in operands: # Create all possible combinations of operands\n",
        "                query_string = to_padded_chars(str(i) + sign + str(j), max_len=max_query_length, pad_right=False)\n",
        "                query_image = []\n",
        "                for n, char in enumerate(query_string):\n",
        "                    image_set = image_mapping[char]\n",
        "                    index = np.random.randint(0, len(image_set), 1)\n",
        "                    query_image.append(image_set[index].squeeze())\n",
        "\n",
        "                result = eval(query_string)\n",
        "                result_string = to_padded_chars(result, max_len=max_answer_length, pad_right=False)\n",
        "                result_image = []\n",
        "                for n, char in enumerate(result_string):\n",
        "                    image_set = image_mapping[char]\n",
        "                    index = np.random.randint(0, len(image_set), 1)\n",
        "                    result_image.append(image_set[index].squeeze())\n",
        "\n",
        "                X_text.append(query_string)\n",
        "                X_img.append(np.stack(query_image))\n",
        "                y_text.append(result_string)\n",
        "                y_img.append(np.stack(result_image))\n",
        "\n",
        "    return np.stack(X_text), np.stack(X_img)/255., np.stack(y_text), np.stack(y_img)/255.\n",
        "\n",
        "def to_padded_chars(integer, max_len=3, pad_right=False):\n",
        "    \"\"\"\n",
        "    Returns a string of len()=max_len, containing the integer padded with ' ' on either right or left side\n",
        "    \"\"\"\n",
        "    length = len(str(integer))\n",
        "    padding = (max_len - length) * ' '\n",
        "    if pad_right:\n",
        "        return str(integer) + padding\n",
        "    else:\n",
        "        return padding + str(integer)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bTMHYBf4baih"
      },
      "source": [
        "# Creating our data\n",
        "\n",
        "The dataset consists of 20000 samples that (additions and subtractions between all 2-digit integers) and they have two kinds of inputs and label modalities:\n",
        "\n",
        "  **X_text**: strings containing queries of length 5: ['  1+1  ', '11-18', ...]\n",
        "\n",
        "  **X_image**: a stack of images representing a single query, dimensions: [5, 28, 28]\n",
        "\n",
        "  **y_text**: strings containing answers of length 3: ['  2', '156']\n",
        "\n",
        "  **y_image**: a stack of images that represents the answer to a query, dimensions: [3, 28, 28]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "y0N1vtdLJmkG",
        "outputId": "9cdffe31-4f7c-4e56-902e-ac6acc221c67",
        "scrolled": false
      },
      "outputs": [],
      "source": [
        "X_text, X_img, y_text, y_img = create_data(unique_characters, highest_integer) \n",
        "X_text, X_img, y_text, y_img = shuffle(X_text, X_img, y_text, y_img, random_state=42)\n",
        "\n",
        "print(X_text.shape, X_img.shape, y_text.shape, y_img.shape)\n",
        "\n",
        "## Display the samples that were created\n",
        "def display_sample(n):\n",
        "    labels = ['X_img:', 'y_img:']\n",
        "    for i, data in enumerate([X_img, y_img]):\n",
        "        plt.subplot(1,2,i+1)\n",
        "        # plt.set_figheight(15)\n",
        "        plt.axis('off')\n",
        "        plt.title(labels[i])\n",
        "        plt.imshow(np.hstack(data[n]), cmap='gray')\n",
        "    print('='*50, f'\\nQuery #{n}\\n\\nX_text: \"{X_text[n]}\" = y_text: \"{y_text[n]}\"')\n",
        "    plt.show()\n",
        "\n",
        "for _ in range(10):\n",
        "    display_sample(np.random.randint(0, 10000, 1)[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h06Gi5l63EvS"
      },
      "source": [
        "## Helper functions\n",
        "\n",
        "The functions below will help with input/output of the data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rePVm6duJmkJ",
        "outputId": "c48e6478-4c67-492e-975b-9fa6e4a2d669"
      },
      "outputs": [],
      "source": [
        "# One-hot encoding/decoding the text queries/answers so that they can be processed using RNNs\n",
        "# You should use these functions to convert your strings and read out the output of your networks\n",
        "\n",
        "def encode_labels(labels, max_len=3):\n",
        "  n = len(labels)\n",
        "  length = len(labels[0])\n",
        "  char_map = dict(zip(unique_characters, range(len(unique_characters))))\n",
        "  one_hot = np.zeros([n, length, len(unique_characters)])\n",
        "  for i, label in enumerate(labels):\n",
        "      m = np.zeros([length, len(unique_characters)])\n",
        "      for j, char in enumerate(label):\n",
        "          m[j, char_map[char]] = 1\n",
        "      one_hot[i] = m\n",
        "\n",
        "  return one_hot\n",
        "\n",
        "\n",
        "def decode_labels(labels):\n",
        "    pred = np.argmax(labels, axis=1)\n",
        "    predicted = ''.join([unique_characters[i] for i in pred])\n",
        "\n",
        "    return predicted\n",
        "\n",
        "X_text_onehot = encode_labels(X_text)\n",
        "y_text_onehot = encode_labels(y_text)\n",
        "\n",
        "# print(X_text_onehot.shape, y_text_onehot.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7-pNByj-JmkL"
      },
      "source": [
        "---\n",
        "---\n",
        "\n",
        "## I. Text-to-text RNN model\n",
        "\n",
        "The following code showcases how Recurrent Neural Networks (RNNs) are built using Keras. Several new layers are going to be used:\n",
        "\n",
        "1. LSTM\n",
        "2. TimeDistributed\n",
        "3. RepeatVector\n",
        "\n",
        "The code cell below explains each of these new components.\n",
        "\n",
        "<img src=\"https://i.ibb.co/NY7FFTc/Screenshot-2023-11-10-at-09-27-25.png\" alt=\"Screenshot-2023-11-10-at-09-27-25\" border=\"0\" width=\"500\"></a>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tll54DIrZwbK"
      },
      "outputs": [],
      "source": [
        "def build_text2text_model():\n",
        "\n",
        "    # We start by initializing a sequential model\n",
        "    text2text = tf.keras.Sequential()\n",
        "\n",
        "    # \"Encode\" the input sequence using an RNN, producing an output of size 256.\n",
        "    # In this case the size of our input vectors is [5, 13] as we have queries of length 5 and 13 unique characters. Each of these 5 elements in the query will be fed to the network one by one,\n",
        "    # as shown in the image above (except with 5 elements).\n",
        "    # Hint: In other applications, where your input sequences have a variable length (e.g. sentences), you would use input_shape=(None, unique_characters).\n",
        "    text2text.add(LSTM(256, input_shape=(None, len(unique_characters))))\n",
        "\n",
        "    # As the decoder RNN's input, repeatedly provide with the last output of RNN for each time step. Repeat 3 times as that's the maximum length of the output (e.g. '  1-99' = '-98')\n",
        "    # when using 2-digit integers in queries. In other words, the RNN will always produce 3 characters as its output.\n",
        "    text2text.add(RepeatVector(max_answer_length))\n",
        "\n",
        "    # By setting return_sequences to True, return not only the last output but all the outputs so far in the form of (num_samples, timesteps, output_dim). This is necessary as TimeDistributed in the below expects\n",
        "    # the first dimension to be the timesteps.\n",
        "    text2text.add(LSTM(256, return_sequences=True))\n",
        "\n",
        "    # Apply a dense layer to the every temporal slice of an input. For each of step of the output sequence, decide which character should be chosen.\n",
        "    text2text.add(TimeDistributed(Dense(len(unique_characters), activation='softmax')))\n",
        "\n",
        "    # Next we compile the model using categorical crossentropy as our loss function.\n",
        "    text2text.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "    text2text.summary()\n",
        "\n",
        "    return text2text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mz6QkPAdzywk"
      },
      "outputs": [],
      "source": [
        "# Analyze the code for generating numerical and image queries and their respective answers from MNIST\n",
        "# data. Inspect the provided text-to-text RNN model and try to understand the dimensionality of the\n",
        "# inputs and output tensors as well as how they are encoded/decoded (one-hot format).\n",
        "\n",
        "# Set seeds for reproducibility\n",
        "random_seed = 42\n",
        "random.seed(random_seed)\n",
        "np.random.seed(random_seed)\n",
        "tf.random.set_seed(random_seed)\n",
        "\n",
        "if run_text2text_53:\n",
        "\n",
        "    def get_predictions_and_true_labels(model, X_test, y_test):\n",
        "        predictions = model.predict(X_test)\n",
        "        predictions = np.argmax(predictions, axis=-1)\n",
        "        true_labels = np.argmax(y_test, axis=-1)\n",
        "        return predictions, true_labels\n",
        "\n",
        "    def display_misclassified_examples(X_test, y_test, model, decode_labels, num_examples=10):\n",
        "        misclassified = []\n",
        "        for i in range(len(X_test)):\n",
        "            pred = model.predict(np.array([X_test[i]]))\n",
        "            decoded_pred = decode_labels(pred[0])\n",
        "            decoded_true = decode_labels(y_test[i])\n",
        "            if decoded_pred.strip() != decoded_true.strip():\n",
        "                misclassified.append((X_test[i], decoded_true, decoded_pred))\n",
        "            if len(misclassified) >= num_examples:\n",
        "                break\n",
        "\n",
        "        print(f\"Showing {num_examples} misclassified examples:\")\n",
        "        for example in misclassified:\n",
        "            print(\"Input: \", decode_labels(example[0]))\n",
        "            print(\"Actual: \", example[1].strip())\n",
        "            print(\"Predicted: \", example[2].strip())\n",
        "            print(\"-\" * 30)\n",
        "\n",
        "    def build_text2text_model(unique_characters, max_answer_length, learning_rate, dropout_rate):\n",
        "        text2text = tf.keras.Sequential()\n",
        "        text2text.add(LSTM(256, input_shape=(None, len(unique_characters))))\n",
        "        text2text.add(RepeatVector(max_answer_length))\n",
        "        text2text.add(LSTM(256, return_sequences=True))\n",
        "        text2text.add(Dropout(dropout_rate))  # Dropout after the second LSTM layer to reduce overfitting\n",
        "        text2text.add(TimeDistributed(Dense(len(unique_characters), activation='softmax')))\n",
        "\n",
        "        # Define the optimizer with the desired learning rate\n",
        "        adam_optimizer = Adam(learning_rate=learning_rate)\n",
        "\n",
        "        # Compile the model with the custom optimizer\n",
        "        text2text.compile(loss='categorical_crossentropy', optimizer=adam_optimizer, metrics=['accuracy'])\n",
        "        text2text.summary()\n",
        "        plot_model(text2text, to_file='./figures/model_text2text_plot.png', show_shapes=True, show_layer_names=True)\n",
        "\n",
        "        return text2text\n",
        "\n",
        "\n",
        "    def main(learning_rate, dropout_rate, epochs, test_size):\n",
        "        unique_characters = '0123456789+- '\n",
        "        highest_integer = 99\n",
        "        max_answer_length = 3\n",
        "\n",
        "        epochs=epochs\n",
        "        dropout_rate=dropout_rate\n",
        "        learning_rate=learning_rate\n",
        "        patience_early_stopping=10 # patience: stop if train loss fails to reduce \n",
        "        patience_learning_rate=5   # patience: reduce lr if val loss fails to reduce\n",
        "\n",
        "        X_text, X_img, y_text, y_img = create_data(highest_integer)\n",
        "        X_text, X_img, y_text, y_img = shuffle(X_text, X_img, y_text, y_img, random_state=random_seed)\n",
        "\n",
        "        X_text_onehot = encode_labels(X_text)\n",
        "        y_text_onehot = encode_labels(y_text)\n",
        "\n",
        "        # Split the dataset into a training set and a temporary set (combining validation and test) which is split the same way\n",
        "        X_train, X_temp, y_train, y_temp = train_test_split(X_text_onehot, y_text_onehot, test_size=test_size, random_state=random_seed)\n",
        "        X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=test_size, random_state=random_seed)\n",
        "    \n",
        "        text2text_model = build_text2text_model(unique_characters, max_answer_length, learning_rate, dropout_rate)\n",
        "\n",
        "        # Define callbacks\n",
        "        callbacks = [EarlyStopping(monitor='val_loss', patience=patience_early_stopping, verbose=1),\n",
        "                    ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=patience_learning_rate, min_lr=1.e-5, verbose=1),\n",
        "                    TensorBoard(log_dir=\"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"), histogram_freq=1)]\n",
        "\n",
        "        # Training the model with callbacks\n",
        "        text2text_model.fit(X_train, y_train, epochs=epochs, batch_size=128, validation_data=(X_val, y_val), callbacks=callbacks)\n",
        "\n",
        "        predictions, true_labels = get_predictions_and_true_labels(text2text_model, X_test, y_test)\n",
        "        \n",
        "        # Generate a confusion matrix\n",
        "        conf_matrix = confusion_matrix(true_labels.flatten(), predictions.flatten())\n",
        "\n",
        "        # Generate a classification report\n",
        "        unique_labels = np.unique(np.concatenate([true_labels.flatten(), predictions.flatten()]))\n",
        "        class_report = classification_report(true_labels.flatten(), predictions.flatten(), labels=unique_labels, target_names=[unique_characters[i] for i in unique_labels])\n",
        "\n",
        "        print(\"Confusion Matrix:\\n\", conf_matrix)\n",
        "        print(\"\\nClassification Report:\\n\", class_report)\n",
        "\n",
        "        # Evaluating the model\n",
        "        _, test_acc = text2text_model.evaluate(X_test, y_test)\n",
        "        print(f\"Test Accuracy: {test_acc}\")\n",
        "\n",
        "        # Call this function after training and evaluating your model\n",
        "        display_misclassified_examples(X_test, y_test, text2text_model, decode_labels)\n",
        "\n",
        "        # Making a prediction\n",
        "        sample_problem = encode_labels(np.array(['23+17']))\n",
        "        predicted_solution = text2text_model.predict(sample_problem)\n",
        "        decoded_solution = decode_labels(predicted_solution[0])\n",
        "        print(f\"Predicted Solution: {decoded_solution}\")\n",
        "\n",
        "        return test_acc\n",
        "\n",
        "    if __name__ == \"__main__\":\n",
        "        epochs=200\n",
        "        test_size=0.1\n",
        "        learning_rate=1.e-3\n",
        "        dropout_rate=0.1\n",
        "\n",
        "        # ceate a loop on test sizes to see performance\n",
        "        test_accuracies = []\n",
        "        test_sizes = np.arange(0.1, 1.0, 0.1)  \n",
        "        for test_size in test_sizes:\n",
        "            test_accuracy = main(learning_rate, dropout_rate, epochs, test_size)\n",
        "            test_accuracies.append(test_accuracy)\n",
        "\n",
        "        # keep results\n",
        "        np.savez('./results/text2text_test_performance.npz', test_sizes=test_sizes, test_accuracies=test_accuracies)\n",
        "        print(\"Data saved successfully.\")\n",
        "\n",
        "        # exit with a plot for inclusion in report\n",
        "        plt.plot(test_sizes, test_accuracies)\n",
        "        plt.scatter(test_sizes, test_accuracies, marker='*', s=50)\n",
        "\n",
        "        # loop through each point to place a text label\n",
        "        for i, txt in enumerate(test_accuracies):\n",
        "            plt.text(test_sizes[i], test_accuracies[i] - 0.01, f'{txt:.2f}', ha='center', va='top')  \n",
        "\n",
        "        plt.xlabel('test_size t')\n",
        "        plt.ylabel('Test Accuracy')\n",
        "        plt.ylim([0, 1])\n",
        "        plt.title('text2text_53 Model Performance Across Test Sizes')\n",
        "        plt.tight_layout()\n",
        "        plt.savefig('./figures/experiment_1: text2text_53 accuracy across test sizes.pdf')\n",
        "        plt.show()\n",
        "            \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MTUqbQrbaKfB"
      },
      "source": [
        "\n",
        "---\n",
        "---\n",
        "\n",
        "## II. Image to text RNN Model\n",
        "\n",
        "Hint: There are two ways of building the encoder for such a model - again by using the regular LSTM cells (with flattened images as vectors) or recurrect convolutional layers [ConvLSTM2D](https://keras.io/api/layers/recurrent_layers/conv_lstm2d/).\n",
        "\n",
        "The goal here is to use **X_img** as inputs and **y_text** as outputs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5Kv1ZBYqHTG3"
      },
      "outputs": [],
      "source": [
        "# Create an image-to-text RNN model: given a sequence of MNIST images that represent a query of an\n",
        "# arithmetic operation, your model should return the answer in text format. Once you have trained your\n",
        "# model, evaluate its accuracy and compare it to the text-to-text model.\n",
        "\n",
        "# Set seeds for reproducibility\n",
        "random_seed = 42\n",
        "random.seed(random_seed)\n",
        "np.random.seed(random_seed)\n",
        "tf.random.set_seed(random_seed)\n",
        "\n",
        "if run_image2text_53:\n",
        "\n",
        "    def build_image2text_model(input_shape, unique_characters, max_answer_length, learning_rate=0.001, dropout_rate=0.1):\n",
        "        image2text = models.Sequential()\n",
        "\n",
        "        image2text.add(layers.Reshape((input_shape[0], 28, 28, 1), input_shape=input_shape))        \n",
        "        # TimeDistributed Convolutional layers for feature extraction\n",
        "        image2text.add(layers.TimeDistributed(layers.Conv2D(32, (3, 3), activation='relu')))\n",
        "        image2text.add(layers.TimeDistributed(layers.MaxPooling2D((2, 2))))\n",
        "        image2text.add(layers.TimeDistributed(layers.Conv2D(64, (3, 3), activation='relu')))\n",
        "        image2text.add(layers.TimeDistributed(layers.MaxPooling2D((2, 2))))\n",
        "        image2text.add(layers.TimeDistributed(layers.Conv2D(64, (3, 3), activation='relu')))\n",
        "\n",
        "        # flatten the output for the LSTM layers\n",
        "        image2text.add(layers.TimeDistributed(layers.Flatten()))\n",
        "\n",
        "        # LSTM layers for understanding the sequence\n",
        "        image2text.add(layers.LSTM(64, return_sequences=True))\n",
        "        image2text.add(layers.LSTM(64))\n",
        "\n",
        "        # dense layers for interpretation and output\n",
        "        image2text.add(layers.Dense(64, activation='relu'))\n",
        "        image2text.add(layers.Dropout(dropout_rate))\n",
        "        image2text.add(layers.Dense(len(unique_characters) * max_answer_length, activation='softmax'))\n",
        "\n",
        "        # reshape to match the output format\n",
        "        image2text.add(layers.Reshape((max_answer_length, len(unique_characters))))\n",
        "\n",
        "        # define the optimizer with the desired learning rate\n",
        "        adam_optimizer = optimizers.Adam(learning_rate=learning_rate)\n",
        "\n",
        "        # compile the model with the custom optimizer\n",
        "        image2text.compile(optimizer=adam_optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "        image2text.summary()\n",
        "        # plot model for inclusion in report\n",
        "        plot_model(image2text, to_file='./figures/model_text2text_plot.png', show_shapes=True, show_layer_names=True)\n",
        "        return image2text\n",
        "\n",
        "    # alternative model - tried but did not yield superior results\n",
        "    # def build_convLSTM_dense_image2text_model(input_shape, unique_characters, max_answer_length, learning_rate=0.001, dropout_rate=0.1):\n",
        "    #     model = models.Sequential()\n",
        "\n",
        "    #     # Adjusted pooling sizes\n",
        "    #     pooling_size_3 = (1, 3, 3)  \n",
        "    #     pooling_size_2 = (1, 2, 2)  \n",
        "    #     pooling_size_1 = (1, 1, 2)  # Reduced pooling size for later layers\n",
        "\n",
        "    #     # ConvLSTM2D layers for spatiotemporal feature extraction\n",
        "    #     model.add(layers.ConvLSTM2D(32, (5, 5), padding='same', return_sequences=True, input_shape=input_shape))\n",
        "    #     model.add(layers.BatchNormalization())\n",
        "    #     model.add(layers.MaxPooling3D(pool_size=pooling_size_3))  \n",
        "\n",
        "    #     model.add(layers.ConvLSTM2D(32, (5, 5), padding='same', return_sequences=True))\n",
        "    #     model.add(layers.BatchNormalization())\n",
        "    #     model.add(layers.MaxPooling3D(pool_size=pooling_size_2))  \n",
        "\n",
        "    #     model.add(layers.ConvLSTM2D(32, (5, 5), padding='same', return_sequences=True))\n",
        "    #     model.add(layers.BatchNormalization())\n",
        "    #     model.add(layers.MaxPooling3D(pool_size=pooling_size_1))\n",
        "\n",
        "    #     model.add(layers.ConvLSTM2D(64, (3, 3), padding='same', return_sequences=False))\n",
        "    #     model.add(layers.BatchNormalization())\n",
        "\n",
        "    #     # Flatten the output for the Dense layers\n",
        "    #     model.add(layers.Flatten())\n",
        "\n",
        "    #     # Dense layers for interpretation and output\n",
        "    #     model.add(layers.Dense(64, activation='relu'))\n",
        "    #     model.add(layers.Dropout(dropout_rate))\n",
        "    #     model.add(layers.Dense(len(unique_characters) * max_answer_length, activation='softmax'))\n",
        "\n",
        "    #     # Reshape to match the output format\n",
        "    #     model.add(layers.Reshape((max_answer_length, len(unique_characters))))\n",
        "\n",
        "    #     # Define the optimizer with the desired learning rate\n",
        "    #     adam_optimizer = optimizers.Adam(learning_rate=learning_rate)\n",
        "\n",
        "    #     # Compile the model with the custom optimizer\n",
        "    #     model.compile(optimizer=adam_optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    #     model.summary()\n",
        "\n",
        "    #     return model\n",
        "\n",
        "    def main(learning_rate, dropout_rate, epochs, test_size):\n",
        "        unique_characters = '0123456789+- '\n",
        "        highest_integer = 99\n",
        "        max_answer_length = 3\n",
        "\n",
        "        random_seed=42\n",
        "        epochs=epochs\n",
        "        dropout_rate=dropout_rate\n",
        "        learning_rate=learning_rate\n",
        "        patience_early_stopping=50\n",
        "        patience_learning_rate=5\n",
        "\n",
        "        # Generate the dataset\n",
        "        X_text, X_img, y_text, y_img = create_data(unique_characters, highest_integer)\n",
        "        X_text, X_img, y_text, y_img = shuffle(X_text, X_img, y_text, y_img, random_state=random_seed)\n",
        "\n",
        "        # Preprocess images for LSTM\n",
        "        X_img_preprocessed = X_img.reshape(X_img.shape[0], X_img.shape[1], 28, 28, 1)\n",
        "        y_text_onehot = encode_labels(y_text)  # Implement encode_labels accordingly\n",
        "\n",
        "        # Splitting the dataset\n",
        "        X_train, X_temp, y_train, y_temp = train_test_split(X_img_preprocessed, y_text_onehot, test_size=test_size, random_state=random_seed)\n",
        "        X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=test_size, random_state=random_seed)\n",
        "\n",
        "        # Building the model\n",
        "        model = build_image2text_model(X_train.shape[1:], unique_characters, max_answer_length, learning_rate, dropout_rate)\n",
        "\n",
        "        # Define callbacks\n",
        "        callbacks = [EarlyStopping(monitor='val_loss', patience=patience_early_stopping, verbose=1),\n",
        "                    ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=patience_learning_rate, min_lr=1.e-5, verbose=1),\n",
        "                    TensorBoard(log_dir=\"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"), histogram_freq=1)]\n",
        "\n",
        "        history=model.fit(X_train, y_train, epochs=epochs, batch_size=128, validation_data=(X_val, y_val), callbacks=callbacks)\n",
        "\n",
        "        _, test_acc = model.evaluate(X_test, y_test)\n",
        "        print(f\"Test Accuracy: {test_acc}\")\n",
        "        np.save('./results/image2text_training_history.npy', history.history)\n",
        "        model.save('./models/image2text_model.h5')\n",
        "\n",
        "        return test_acc\n",
        "\n",
        "    \n",
        "    if __name__ == \"__main__\":\n",
        "\n",
        "        epochs=400\n",
        "        learning_rate=1.e-3\n",
        "        dropout_rate=0.2\n",
        "        unique_characters = '0123456789+- '\n",
        "\n",
        "        test_sizes = np.arange(0.1, 1.0, 0.2)  \n",
        "        for test_size in test_sizes:\n",
        "            test_accuracy=main(learning_rate, dropout_rate, epochs, test_size)\n",
        "                \n",
        "            np.savez(f'./results/image2text_53_test_performance_{test_size}.npz', \n",
        "                test_sizes=test_sizes, \n",
        "                test_accuracies=test_accuracy)\n",
        "                \n",
        "            print(\"Data saved successfully.\")\n",
        "\n",
        "        plt.plot(test_sizes, test_accuracy)\n",
        "        plt.scatter(test_sizes, test_accuracy, marker='*', s=50)\n",
        "        for i, txt in enumerate(test_accuracy):\n",
        "            plt.text(test_sizes[i], test_accuracy[i], f'{txt:.4f}', ha='center', va='top')  \n",
        "\n",
        "        plt.xlabel('test_size t')\n",
        "        plt.ylabel('Test Accuracy')\n",
        "        plt.ylim([0, 1])\n",
        "        plt.title('image2text_53 model performance across different test sizes')\n",
        "        plt.tight_layout()\n",
        "        plt.savefig('./figures/experiment_2 image2text_53 accuracy.pdf')\n",
        "        plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# visualize the results of training (not used in report)\n",
        "\n",
        "if run_image2text_53:\n",
        "\n",
        "    # Load the training history\n",
        "    history = np.load('./results/image2text_training_history.npy', allow_pickle='TRUE').item()\n",
        "\n",
        "    # Plot the training and validation loss\n",
        "    plt.figure(figsize=(12, 5))\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(history['loss'], label='Training Loss')\n",
        "    plt.plot(history['val_loss'], label='Validation Loss')\n",
        "    plt.title('Training and Validation Loss')\n",
        "    plt.yscale('log')\n",
        "    plt.grid(which='major', axis='both', linestyle='-', linewidth='0.5')  # Major grid for both axes\n",
        "    plt.grid(which='minor', axis='y', linestyle=':', linewidth='0.5')  # Minor grid for y-axis\n",
        "    plt.minorticks_on()  # Enable minor ticks on y-axis\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "\n",
        "    # Plot the training and validation accuracy\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(history['accuracy'], label='Training Accuracy')\n",
        "    plt.plot(history['val_accuracy'], label='Validation Accuracy')\n",
        "    plt.title('Training and Validation Accuracy')\n",
        "    plt.grid(which='major', axis='both', linestyle='-', linewidth='0.5')  # Major grid for both axes\n",
        "    plt.grid(which='minor', axis='y', linestyle=':', linewidth='0.5')  # Minor grid for y-axis\n",
        "    plt.minorticks_on()  # Enable minor ticks on y-axis\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.legend()\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('./figures/Fig_3_learning_curves.pdf')\n",
        "    plt.show()\n",
        "\n",
        "    # Summarize Performance Statistics\n",
        "    final_train_loss = history['loss'][-1]\n",
        "    final_val_loss = history['val_loss'][-1]\n",
        "    final_train_accuracy = history['accuracy'][-1]\n",
        "    final_val_accuracy = history['val_accuracy'][-1]\n",
        "\n",
        "    print(f\"Final Training Loss: {final_train_loss:.4f}\")\n",
        "    print(f\"Final Validation Loss: {final_val_loss:.4f}\")\n",
        "    print(f\"Final Training Accuracy: {final_train_accuracy:.4f}\")\n",
        "    print(f\"Final Validation Accuracy: {final_val_accuracy:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GnGyo_DIlymz"
      },
      "source": [
        "---\n",
        "---\n",
        "\n",
        "## III. Text to image RNN Model\n",
        "\n",
        "Hint: to make this model work really well you could use deconvolutional layers in your decoder (you might need to look up ***Conv2DTranspose*** layer). However, regular vector-based decoder will work as well.\n",
        "\n",
        "The goal here is to use **X_text** as inputs and **y_img** as outputs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KwhT9fiW7p_t"
      },
      "outputs": [],
      "source": [
        "# Build a text-to-image RNN model: given a text query, your network should generate a sequence of\n",
        "# images that represent the correct answer. In this case, it is harder to evaluate the performance of your\n",
        "# model qualitatively. However, you should provide examples of the output generated by your model in\n",
        "# the report. What can you say about the appearance of these generated images?\n",
        "\n",
        "if run_text2image_53:\n",
        "       \n",
        "    def classify_digits(mnist_model, image):\n",
        "        # Preprocess the image (reshape, normalize, etc.) as done for MNIST training\n",
        "        # Ensure the image is reshaped to (1, 28, 28, 1)\n",
        "        image_preprocessed = image.reshape(1, 28, 28, 1) / 255.0\n",
        "        # Predict the digit class\n",
        "        digit_prediction = mnist_model.predict(image_preprocessed)\n",
        "        return np.argmax(digit_prediction, axis=1)\n",
        "\n",
        "    def calculate_accuracy(true_labels, predicted_labels):\n",
        "        correct = np.sum(true_labels == predicted_labels)\n",
        "        total = len(true_labels)\n",
        "        return correct / total\n",
        "\n",
        "    def create_data(unique_characters, highest_integer, num_addends=2, operands=['+', '-']):\n",
        "        \"\"\"\n",
        "        Creates the following data for all pairs of integers up to [1:highest integer][+/-][1:highest_integer]:\n",
        "\n",
        "        @return:\n",
        "        X_text: '51+21' -> text query of an arithmetic operation (5)\n",
        "        X_img : Stack of MNIST images corresponding to the query (5 x 28 x 28) -> sequence of 5 images of size 28x28\n",
        "        y_text: '72' -> answer of the arithmetic text query\n",
        "        y_img :  Stack of MNIST images corresponding to the answer (3 x 28 x 28)\n",
        "\n",
        "        Images for digits are picked randomly from the whole MNIST dataset.\n",
        "        \"\"\"\n",
        "        (MNIST_data, MNIST_labels), _ = tf.keras.datasets.mnist.load_data()\n",
        "        max_int_length = len(str(highest_integer))# Maximum number of characters in an integer\n",
        "        max_query_length = max_int_length * 2 + 1 # Maximum length of the query string (consists of two integers and an operand [e.g. '22+10'])\n",
        "        max_answer_length = max_int_length + 1    # Maximum length of the answer string (the longest resulting query string is ' 1-99'='-98')\n",
        "        num_indices = [np.where(MNIST_labels==x) for x in range(10)]\n",
        "        num_data = [MNIST_data[inds] for inds in num_indices]\n",
        "        \n",
        "        image_mapping = dict(zip(unique_characters[:10], num_data))\n",
        "        image_mapping['-'] = generate_images()\n",
        "        image_mapping['+'] = generate_images(sign='+')\n",
        "        image_mapping['*'] = generate_images(sign='*')\n",
        "        image_mapping[' '] = np.zeros([1, 28, 28])\n",
        "\n",
        "        X_text, X_img, y_text, y_img = [], [], [], []\n",
        "\n",
        "        for i in range(highest_integer + 1):      # First addend\n",
        "            for j in range(highest_integer + 1):  # Second addend\n",
        "                for sign in operands: # Create all possible combinations of operands\n",
        "                    query_string = to_padded_chars(str(i) + sign + str(j), max_len=max_query_length, pad_right=False)\n",
        "                    query_image = []\n",
        "                    for n, char in enumerate(query_string):\n",
        "                        image_set = image_mapping[char]\n",
        "                        index = np.random.randint(0, len(image_set), 1)\n",
        "                        query_image.append(image_set[index].squeeze())\n",
        "\n",
        "                    result = eval(query_string)\n",
        "                    result_string = to_padded_chars(result, max_len=max_answer_length, pad_right=False)\n",
        "                    result_image = []\n",
        "                    for n, char in enumerate(result_string):\n",
        "                        image_set = image_mapping[char]\n",
        "                        index = np.random.randint(0, len(image_set), 1)\n",
        "                        result_image.append(image_set[index].squeeze())\n",
        "\n",
        "                    X_text.append(query_string)\n",
        "                    X_img.append(np.stack(query_image))\n",
        "                    y_text.append(result_string)\n",
        "                    y_img.append(np.stack(result_image))\n",
        "\n",
        "        return np.stack(X_text), np.stack(X_img)/255., np.stack(y_text), np.stack(y_img)/255.\n",
        "\n",
        "    def display_samples(X_text, y_true, y_pred, sample_indices):\n",
        "        plt.figure(figsize=(5, 10))  \n",
        "\n",
        "        for i, idx in enumerate(sample_indices):\n",
        "            # Display true images\n",
        "            plt.subplot(10, 2, 2*i + 1)\n",
        "            plt.imshow(np.hstack(y_true[idx]), cmap='gray')\n",
        "            plt.title(f\"True Images for {i+1}:  {str(X_text[idx])}\")\n",
        "            plt.axis('off')\n",
        "\n",
        "            # Display predicted images\n",
        "            plt.subplot(10, 2, 2*i + 2)\n",
        "            plt.imshow(np.hstack(y_pred[idx].squeeze()), cmap='gray')\n",
        "            plt.title(f\"Predicted Images for {i+1}:  {str(X_text[idx])}\")\n",
        "            plt.axis('off')\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(f'./figures/text2image_53_ts{test_size:2.1f}_ep{epochs}_nl{num_layers}_final.pdf')\n",
        "        plt.show()\n",
        "\n",
        "    def build_text2image_model(unique_characters, digit_image_shape, learning_rate, dropout_rate, num_lstm_layers):\n",
        "        # Text processing part (RNN)\n",
        "        text_input = layers.Input(shape=(None, len(unique_characters)))\n",
        "        x = layers.LSTM(256, return_sequences=True)(text_input)\n",
        "        x = layers.LSTM(256)(x)\n",
        "        x = layers.Dropout(dropout_rate)(x)\n",
        "\n",
        "        # Image generation part\n",
        "        num_segments = 3  # Number of images in the sequence\n",
        "        segment_outputs = []\n",
        "        for _ in range(num_segments):\n",
        "            segment = layers.Dense(128, activation='relu')(x)\n",
        "            segment = layers.Dense(np.prod(digit_image_shape), activation='sigmoid')(segment)\n",
        "            segment = layers.Reshape(digit_image_shape)(segment)\n",
        "            segment_outputs.append(segment)\n",
        "\n",
        "        # Output the segments as a sequence\n",
        "        image_output = layers.Lambda(lambda x: tf.stack(x, axis=1))(segment_outputs)\n",
        "\n",
        "        # Build and compile the model\n",
        "        model = models.Model(inputs=text_input, outputs=image_output)\n",
        "        model.compile(optimizer=optimizers.Adam(learning_rate=learning_rate), loss='mean_squared_error')\n",
        "        model.summary()\n",
        "        plot_model(model, to_file='./figures/model_text2image_plot.png', show_shapes=True, show_layer_names=True)\n",
        "        return model\n",
        "\n",
        "\n",
        "    def main(learning_rate, dropout_rate, epochs, test_size):\n",
        "\n",
        "        # data initialization\n",
        "        unique_characters = '0123456789+- '\n",
        "        highest_integer = 99\n",
        "\n",
        "        # architecture\n",
        "        digit_image_shape = (28, 28, 1)  # MNIST image shape\n",
        "\n",
        "        # hyper parameters\n",
        "        random_seed=42\n",
        "        epochs=epochs\n",
        "        dropout_rate=dropout_rate\n",
        "        learning_rate=learning_rate\n",
        "        patience_early_stopping=50\n",
        "        patience_learning_rate=5\n",
        "        \n",
        "        # Generate the dataset\n",
        "        X_text, X_img, y_text, y_img = create_data(unique_characters, highest_integer, num_addends=2, operands=['+', '-'])\n",
        "        X_text, X_img, y_text, y_img = shuffle(X_text, X_img, y_text, y_img, random_state=random_seed)\n",
        "        print(X_text.shape, y_img.shape)\n",
        "        # Preprocess images for LSTM\n",
        "        X_text_onehot = encode_labels(X_text)\n",
        "        y_img_preprocessed = y_img.reshape(y_img.shape[0], y_img.shape[1], 28, 28)\n",
        "        print(X_text_onehot.shape, y_img_preprocessed.shape)\n",
        "\n",
        "        # Splitting the dataset\n",
        "        X_train_onehot, X_temp_onehot, y_train, y_temp, X_train_text, X_temp_text = train_test_split(\n",
        "            X_text_onehot, y_img_preprocessed, X_text, test_size=test_size, random_state=random_seed)\n",
        "\n",
        "        X_val_onehot, X_test_onehot, y_val, y_test, X_val_text, X_test_text = train_test_split(\n",
        "            X_temp_onehot, y_temp, X_temp_text, test_size=test_size, random_state=random_seed)\n",
        "    \n",
        "        model = build_text2image_model(unique_characters, digit_image_shape, learning_rate, dropout_rate, num_layers)\n",
        "        \n",
        "        # Define callbacks\n",
        "        callbacks = [EarlyStopping(monitor='val_loss', patience=patience_early_stopping, verbose=1),\n",
        "                    ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=patience_learning_rate, min_lr=1.e-5, verbose=1),\n",
        "                    TensorBoard(log_dir=\"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"), histogram_freq=1)]\n",
        "\n",
        "        history = model.fit(X_train_onehot, y_train, epochs=epochs, batch_size=128, validation_data=(X_val_onehot, y_val), callbacks=callbacks)        \n",
        "        model.save(f'./models/model_text2image_53_new_e{epochs}_ts{test_size:2.1f}.h5')\n",
        "\n",
        "        # Generate predictions for the test set\n",
        "        predicted_test = model.predict(X_test_onehot)\n",
        "\n",
        "        # Select 10 random test samples\n",
        "        sample_indices = np.random.choice(len(X_test_text), 10, replace=False)\n",
        "\n",
        "        # Display the selected samples\n",
        "        display_samples(X_test_text, y_test, predicted_test, sample_indices)\n",
        "\n",
        "\n",
        "    if __name__ == \"__main__\":\n",
        "\n",
        "        random_seed = 42\n",
        "        random.seed(random_seed)\n",
        "        np.random.seed(random_seed)\n",
        "        tf.random.set_seed(random_seed)\n",
        "\n",
        "        epochs=200\n",
        "        learning_rate=1.e-3\n",
        "        dropout_rate=0.03\n",
        "        unique_characters = '0123456789+- '\n",
        "        highest_integer = 99\n",
        "        num_layers=3\n",
        "\n",
        "        test_accuracies = []\n",
        "        test_sizes = np.arange(0.1, 1.0, 0.2)  \n",
        "\n",
        "        for test_size in test_sizes:\n",
        "            main(learning_rate, dropout_rate, epochs, test_size)\n",
        " \n",
        " "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Try adding additional LSTM layers to your encoder networks and see how the performance of your\n",
        "# models changes. Try to explain these performance differences in the context of the mistakes that\n",
        "# your network was making before. Tip: you should add a flag ”return sequences=True” to the first\n",
        "# recurrent layer of your network."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pAngAFt27NAr"
      },
      "source": [
        "\n",
        "---\n",
        "---\n",
        "---\n",
        "\n",
        "# Part 2: Multiplication\n",
        "The cell below will create the multiplication dataset used in this part of the assignment."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "x8Ouxlop7LvC",
        "outputId": "7ff2a761-fbd9-49c3-e87f-da658c08ebce"
      },
      "outputs": [],
      "source": [
        "# Illustrate the generated query/answer pairs\n",
        "\n",
        "# Now try building models around the multiplication dataset (last cell of the notebook) - one that\n",
        "# contains all combinations of two-digit integer multiplications (10,000 samples).\n",
        "\n",
        "if run_text2text_54 or run_image2text_54:\n",
        "    unique_characters = '0123456789* '       # All unique characters that are used in the queries (13 in total: digits 0-9, 2 operands [+, -], and a space character ' '.)\n",
        "    highest_integer = 99                      # Highest value of integers contained in the queries\n",
        "\n",
        "    max_int_length = len(str(highest_integer))# Maximum number of characters in an integer\n",
        "    max_query_length = max_int_length * 2 + 1 # Maximum length of the query string (consists of two integers and an operand [e.g. '22+10'])\n",
        "    max_answer_length = 5    # Maximum length of the answer string (the longest resulting query string is ' 1-99'='-98')\n",
        "\n",
        "    # Create the data (might take around a minute)\n",
        "    (MNIST_data, MNIST_labels), _ = tf.keras.datasets.mnist.load_data()\n",
        "    X_text, X_img, y_text, y_img = create_data(unique_characters, highest_integer, operands=['*'])\n",
        "    print(X_text.shape, X_img.shape, y_text.shape, y_img.shape)\n",
        "\n",
        "\n",
        "    ## Display the samples that were created\n",
        "    def display_sample(n):\n",
        "        labels = ['X_img:', 'y_img:']\n",
        "        for i, data in enumerate([X_img, y_img]):\n",
        "            plt.subplot(1,2,i+1)\n",
        "            # plt.set_figheight(15)\n",
        "            plt.axis('off')\n",
        "            plt.title(labels[i])\n",
        "            plt.imshow(np.hstack(data[n]), cmap='gray')\n",
        "        print('='*50, f'\\nQuery #{n}\\n\\nX_text: \"{X_text[n]}\" = y_text: \"{y_text[n]}\"')\n",
        "        plt.show()\n",
        "\n",
        "    for _ in range(10):\n",
        "        display_sample(np.random.randint(0, 10000, 1)[0])\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create text-to-text and image-to-text models for the multiplication problem. How do the generalization\n",
        "# capabilities change compared to Task 1?\n",
        "\n",
        "# Analyze the code for generating numerical and image queries and their respective answers from MNIST\n",
        "# data. Inspect the provided text-to-text RNN model and try to understand the dimensionality of the\n",
        "# inputs and output tensors as well as how they are encoded/decoded (one-hot format).\n",
        "\n",
        "# Set seeds for reproducibility\n",
        "random_seed = 42\n",
        "random.seed(random_seed)\n",
        "np.random.seed(random_seed)\n",
        "tf.random.set_seed(random_seed)\n",
        "\n",
        "if run_text2text_54:\n",
        "    def get_predictions_and_true_labels(model, X_test, y_test):\n",
        "        predictions = model.predict(X_test)\n",
        "        predictions = np.argmax(predictions, axis=-1)\n",
        "        true_labels = np.argmax(y_test, axis=-1)\n",
        "        return predictions, true_labels\n",
        "\n",
        "    def display_misclassified_examples(X_test, y_test, model, decode_labels, num_examples=10):\n",
        "        misclassified = []\n",
        "        for i in range(len(X_test)):\n",
        "            pred = model.predict(np.array([X_test[i]]))\n",
        "            decoded_pred = decode_labels(pred[0])\n",
        "            decoded_true = decode_labels(y_test[i])\n",
        "            if decoded_pred.strip() != decoded_true.strip():\n",
        "                misclassified.append((X_test[i], decoded_true, decoded_pred))\n",
        "            if len(misclassified) >= num_examples:\n",
        "                break\n",
        "\n",
        "        print(f\"Showing {num_examples} misclassified examples:\")\n",
        "        for example in misclassified:\n",
        "            print(\"Input: \", decode_labels(example[0]))\n",
        "            print(\"Actual: \", example[1].strip())\n",
        "            print(\"Predicted: \", example[2].strip())\n",
        "            print(\"-\" * 30)\n",
        "\n",
        "    def build_text2text_model(unique_characters, max_answer_length, learning_rate, dropout_rate):\n",
        "        text2text = tf.keras.Sequential()\n",
        "        text2text.add(LSTM(256, input_shape=(None, len(unique_characters))))\n",
        "        text2text.add(RepeatVector(max_answer_length))\n",
        "        text2text.add(LSTM(256, return_sequences=True))\n",
        "        text2text.add(Dropout(dropout_rate))  # Dropout after the second LSTM layer\n",
        "        text2text.add(TimeDistributed(Dense(len(unique_characters), activation='softmax')))\n",
        "\n",
        "        # Define the optimizer with the desired learning rate\n",
        "        adam_optimizer = Adam(learning_rate=learning_rate)\n",
        "\n",
        "        # Compile the model with the custom optimizer\n",
        "        text2text.compile(loss='categorical_crossentropy', optimizer=adam_optimizer, metrics=['accuracy'])\n",
        "        text2text.summary()\n",
        "\n",
        "        return text2text\n",
        "\n",
        "\n",
        "    def main(learning_rate, dropout_rate, epochs, test_size):\n",
        "\n",
        "        epochs=epochs\n",
        "        dropout_rate=dropout_rate\n",
        "        learning_rate=learning_rate\n",
        "        patience_early_stopping=10\n",
        "        patience_learning_rate=5\n",
        "\n",
        "        X_text, X_img, y_text, y_img = create_data(unique_characters, highest_integer, operands=['*'])\n",
        "\n",
        "        X_text_onehot = encode_labels(X_text)\n",
        "        y_text_onehot = encode_labels(y_text)\n",
        "\n",
        "        # Splitting the dataset\n",
        "        # Split the dataset into a training set and a temporary set (combining validation and test)\n",
        "        X_train, X_temp, y_train, y_temp = train_test_split(X_text_onehot, y_text_onehot, test_size=test_size, random_state=random_seed)\n",
        "\n",
        "        # Split the temporary set into validation and test sets\n",
        "        X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=test_size, random_state=random_seed)\n",
        "\n",
        "        text2text_model = build_text2text_model(unique_characters, max_answer_length, learning_rate, dropout_rate)\n",
        "\n",
        "        # Define callbacks\n",
        "        callbacks = [EarlyStopping(monitor='val_loss', patience=patience_early_stopping, verbose=1),\n",
        "                    ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=patience_learning_rate, min_lr=1.e-5, verbose=1),\n",
        "                    TensorBoard(log_dir=\"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"), histogram_freq=1)]\n",
        "\n",
        "        # Training the model with callbacks\n",
        "        text2text_model.fit(X_train, y_train, epochs=epochs, batch_size=128, validation_data=(X_val, y_val), callbacks=callbacks)\n",
        "\n",
        "        predictions, true_labels = get_predictions_and_true_labels(text2text_model, X_test, y_test)\n",
        "        \n",
        "        # Generate a confusion matrix\n",
        "        conf_matrix = confusion_matrix(true_labels.flatten(), predictions.flatten())\n",
        "\n",
        "        # Generate a classification report\n",
        "        unique_labels = np.unique(np.concatenate([true_labels.flatten(), predictions.flatten()]))\n",
        "        class_report = classification_report(true_labels.flatten(), predictions.flatten(), labels=unique_labels, target_names=[unique_characters[i] for i in unique_labels])\n",
        "\n",
        "        print(\"Confusion Matrix:\\n\", conf_matrix)\n",
        "        print(\"\\nClassification Report:\\n\", class_report)\n",
        "\n",
        "        # Evaluating the model\n",
        "        test_loss, test_acc = text2text_model.evaluate(X_test, y_test)\n",
        "        print(f\"Test Accuracy: {test_acc}\")\n",
        "\n",
        "        # Call this function after training and evaluating your model\n",
        "        display_misclassified_examples(X_test, y_test, text2text_model, decode_labels)\n",
        "\n",
        "        # Making a prediction\n",
        "        sample_problem = encode_labels(np.array(['23*17']))\n",
        "        predicted_solution = text2text_model.predict(sample_problem)\n",
        "        decoded_solution = decode_labels(predicted_solution[0])\n",
        "        print(f\"Predicted Solution: {decoded_solution}\")\n",
        "\n",
        "        return test_acc\n",
        "\n",
        "    if __name__ == \"__main__\":\n",
        "        # hyper parameters\n",
        "        epochs=500\n",
        "        learning_rate=1.e-3\n",
        "        dropout_rate=0.1\n",
        "        # problem parameters\n",
        "        unique_characters = '0123456789* '\n",
        "        highest_integer = 99\n",
        "        max_query_length = len(str(highest_integer)) * 2 + 1\n",
        "        max_answer_length = len(str(highest_integer)) * 2\n",
        "\n",
        "        test_accuracies = []\n",
        "        test_sizes = np.arange(0.1, 1.0, 0.1)  # Creates an array from 0.1 to 0.9 with a step of 0.1\n",
        "        for test_size in test_sizes:\n",
        "            test_accuracy = main(learning_rate, dropout_rate, epochs, test_size)\n",
        "            test_accuracies.append(test_accuracy)\n",
        "\n",
        "        # Assuming test_sizes and test_accuracies are defined and contain your data\n",
        "        np.savez('./results/image2text_54_test_performance.npz', test_sizes=test_sizes, test_accuracies=test_accuracies)\n",
        "        print(\"Data saved successfully.\")\n",
        "\n",
        "        plt.plot(test_sizes, test_accuracies)\n",
        "        plt.xlabel('Test Size')\n",
        "        plt.ylabel('Test Accuracy')\n",
        "        plt.title('text2text model performance across different test sizes')\n",
        "        plt.tight_layout()\n",
        "        plt.savefig('./figures/experiment_6: image2text accuracy across test sizes.pdf')\n",
        "        plt.show()\n",
        "            \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'run_image2text_54' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[1;32mc:\\Users\\ayush\\Downloads\\A2\\A2_RNNs.ipynb Cell 23\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/ayush/Downloads/A2/A2_RNNs.ipynb#X31sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mif\u001b[39;00m run_image2text_54:\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/ayush/Downloads/A2/A2_RNNs.ipynb#X31sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     \u001b[39mimport\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mtf\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/ayush/Downloads/A2/A2_RNNs.ipynb#X31sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m \u001b[39mimport\u001b[39;00m layers, models, optimizers\n",
            "\u001b[1;31mNameError\u001b[0m: name 'run_image2text_54' is not defined"
          ]
        }
      ],
      "source": [
        "if run_image2text_54:\n",
        "\n",
        "    import tensorflow as tf\n",
        "    from keras import layers, models, optimizers\n",
        "    import matplotlib.pyplot as plt\n",
        "    import cv2\n",
        "    import numpy as np\n",
        "    import random\n",
        "    from sklearn.model_selection import train_test_split\n",
        "    from sklearn.metrics import confusion_matrix, classification_report\n",
        "    from sklearn.utils import shuffle\n",
        "    from keras.layers import Dense, RNN, LSTM, Flatten, TimeDistributed, LSTMCell\n",
        "    from keras.layers import RepeatVector, Conv2D, SimpleRNN, GRU, Reshape, ConvLSTM2D, Conv2DTranspose\n",
        "    from keras.layers import Conv2D, MaxPooling2D, Reshape, Dropout\n",
        "    from keras.models import Sequential\n",
        "    from keras.optimizers import Adam\n",
        "    from keras.utils import plot_model\n",
        "    from keras.callbacks import EarlyStopping, ReduceLROnPlateau, TensorBoard\n",
        "    from sklearn.model_selection import train_test_split\n",
        "    from scipy.ndimage import rotate\n",
        "    import datetime\n",
        "\n",
        "\n",
        "    # Set seeds for reproducibility\n",
        "    random_seed = 42\n",
        "    random.seed(random_seed)\n",
        "    np.random.seed(random_seed)\n",
        "    tf.random.set_seed(random_seed)\n",
        "\n",
        "    # Create plus/minus operand signs\n",
        "    def generate_images(number_of_images=50, sign='-'):\n",
        "\n",
        "        blank_images = np.zeros([number_of_images, 28, 28])  # Dimensionality matches the size of MNIST images (28x28)\n",
        "        x = np.random.randint(12, 16, (number_of_images, 2)) # Randomized x coordinates\n",
        "        y1 = np.random.randint(6, 10, number_of_images)       # Randomized y coordinates\n",
        "        y2 = np.random.randint(18, 22, number_of_images)     # -||-\n",
        "\n",
        "        for i in range(number_of_images): # Generate n different images\n",
        "            cv2.line(blank_images[i], (y1[i], x[i,0]), (y2[i], x[i, 1]), (255,0,0), 2, cv2.LINE_AA)     # Draw lines with randomized coordinates\n",
        "            if sign == '+':\n",
        "                cv2.line(blank_images[i], (x[i,0], y1[i]), (x[i, 1], y2[i]), (255,0,0), 2, cv2.LINE_AA) # Draw lines with randomized coordinates\n",
        "            if sign == '*':\n",
        "                cv2.line(blank_images[i], (x[i,0], y1[i]), (x[i, 1], y2[i]), (255,0,0), 2, cv2.LINE_AA)\n",
        "                # Rotate 45 degrees\n",
        "                blank_images[i] = rotate(blank_images[i], -50, reshape=False)\n",
        "                cv2.line(blank_images[i], (x[i,0], y1[i]), (x[i, 1], y2[i]), (255,0,0), 2, cv2.LINE_AA)\n",
        "                blank_images[i] = rotate(blank_images[i], -50, reshape=False)\n",
        "                cv2.line(blank_images[i], (x[i,0], y1[i]), (x[i, 1], y2[i]), (255,0,0), 2, cv2.LINE_AA)\n",
        "\n",
        "        return blank_images\n",
        "\n",
        "    def show_generated(images, n=5):\n",
        "        plt.figure(figsize=(2, 2))\n",
        "        for i in range(n**2):\n",
        "            plt.subplot(n, n, i+1)\n",
        "            plt.axis('off')\n",
        "            plt.imshow(images[i])\n",
        "        plt.show()\n",
        "\n",
        "    # unique_characters = '0123456789* '       # All unique characters that are used in the queries (13 in total: digits 0-9, 2 operands [+, -], and a space character ' '.)\n",
        "    # highest_integer = 99                      # Highest value of integers contained in the queries\n",
        "\n",
        "    # max_int_length = len(str(highest_integer))# Maximum number of characters in an integer\n",
        "    # max_query_length = max_int_length * 2 + 1 # Maximum length of the query string (consists of two integers and an operand [e.g. '22+10'])\n",
        "    # max_answer_length = 5    # Maximum length of the answer string (the longest resulting query string is ' 1-99'='-98')\n",
        "\n",
        "\n",
        "    # Create the data (might take around a minute)\n",
        "    # (MNIST_data, MNIST_labels), _ = tf.keras.datasets.mnist.load_data()\n",
        "\n",
        "    def create_data(unique_characters, highest_integer, num_addends=2, operands=['+', '-']):\n",
        "        \"\"\"\n",
        "        Creates the following data for all pairs of integers up to [1:highest integer][+/-][1:highest_integer]:\n",
        "\n",
        "        @return:\n",
        "        X_text: '51+21' -> text query of an arithmetic operation (5)\n",
        "        X_img : Stack of MNIST images corresponding to the query (5 x 28 x 28) -> sequence of 5 images of size 28x28\n",
        "        y_text: '72' -> answer of the arithmetic text query\n",
        "        y_img :  Stack of MNIST images corresponding to the answer (3 x 28 x 28)\n",
        "\n",
        "        Images for digits are picked randomly from the whole MNIST dataset.\n",
        "        \"\"\"\n",
        "        (MNIST_data, MNIST_labels), _ = tf.keras.datasets.mnist.load_data()\n",
        "        max_int_length = len(str(highest_integer))# Maximum number of characters in an integer\n",
        "        max_query_length = max_int_length * 2 + 1 # Maximum length of the query string (consists of two integers and an operand [e.g. '22+10'])\n",
        "        max_answer_length = 4    # Maximum length of the answer string (the longest resulting query string is ' 99*99'='9801')\n",
        "\n",
        "        num_indices = [np.where(MNIST_labels==x) for x in range(10)]\n",
        "        num_data = [MNIST_data[inds] for inds in num_indices]\n",
        "        image_mapping = dict(zip(unique_characters[:10], num_data))\n",
        "        image_mapping['-'] = generate_images()\n",
        "        image_mapping['+'] = generate_images(sign='+')\n",
        "        image_mapping['*'] = generate_images(sign='*')\n",
        "        image_mapping[' '] = np.zeros([1, 28, 28])\n",
        "\n",
        "        X_text, X_img, y_text, y_img = [], [], [], []\n",
        "\n",
        "        for i in range(highest_integer + 1):      # First addend\n",
        "            for j in range(highest_integer + 1):  # Second addend\n",
        "                for sign in operands: # Create all possible combinations of operands\n",
        "                    query_string = to_padded_chars(str(i) + sign + str(j), max_len=max_query_length, pad_right=False)\n",
        "                    query_image = []\n",
        "                    for n, char in enumerate(query_string):\n",
        "                        image_set = image_mapping[char]\n",
        "                        index = np.random.randint(0, len(image_set), 1)\n",
        "                        query_image.append(image_set[index].squeeze())\n",
        "\n",
        "                    result = eval(query_string)\n",
        "                    result_string = to_padded_chars(result, max_len=max_answer_length, pad_right=False)\n",
        "                    result_image = []\n",
        "                    for n, char in enumerate(result_string):\n",
        "                        image_set = image_mapping[char]\n",
        "                        index = np.random.randint(0, len(image_set), 1)\n",
        "                        result_image.append(image_set[index].squeeze())\n",
        "\n",
        "                    X_text.append(query_string)\n",
        "                    X_img.append(np.stack(query_image))\n",
        "                    y_text.append(result_string)\n",
        "                    y_img.append(np.stack(result_image))\n",
        "\n",
        "        return np.stack(X_text), np.stack(X_img)/255., np.stack(y_text), np.stack(y_img)/255.\n",
        "\n",
        "    def to_padded_chars(integer, max_len=3, pad_right=False):\n",
        "        \"\"\"\n",
        "        Returns a string of len()=max_len, containing the integer padded with ' ' on either right or left side\n",
        "        \"\"\"\n",
        "        length = len(str(integer))\n",
        "        padding = (max_len - length) * ' '\n",
        "        if pad_right:\n",
        "            return str(integer) + padding\n",
        "        else:\n",
        "            return padding + str(integer)\n",
        "\n",
        "    def encode_labels(labels, max_len=3):\n",
        "        n = len(labels)\n",
        "        length = len(labels[0])\n",
        "        char_map = dict(zip(unique_characters, range(len(unique_characters))))\n",
        "        one_hot = np.zeros([n, length, len(unique_characters)])\n",
        "        for i, label in enumerate(labels):\n",
        "            m = np.zeros([length, len(unique_characters)])\n",
        "            for j, char in enumerate(label):\n",
        "                m[j, char_map[char]] = 1\n",
        "            one_hot[i] = m\n",
        "\n",
        "        return one_hot\n",
        "\n",
        "    def decode_labels(labels):\n",
        "        pred = np.argmax(labels, axis=1)\n",
        "        predicted = ''.join([unique_characters[i] for i in pred])\n",
        "\n",
        "        return predicted\n",
        "\n",
        "    def get_predictions_and_true_labels(model, X_test, y_test):\n",
        "        predictions = model.predict(X_test)\n",
        "        predictions = np.argmax(predictions, axis=-1)\n",
        "        true_labels = np.argmax(y_test, axis=-1)\n",
        "        return predictions, true_labels\n",
        "\n",
        "    def display_misclassified_examples(X_test, y_test, model, decode_labels, num_examples=10):\n",
        "        misclassified = []\n",
        "        for i in range(len(X_test)):\n",
        "            pred = model.predict(np.array([X_test[i]]))\n",
        "            decoded_pred = decode_labels(pred[0])\n",
        "            decoded_true = decode_labels(y_test[i])\n",
        "            if decoded_pred.strip() != decoded_true.strip():\n",
        "                misclassified.append((X_test[i], decoded_true, decoded_pred))\n",
        "            if len(misclassified) >= num_examples:\n",
        "                break\n",
        "\n",
        "        print(f\"Showing {num_examples} misclassified examples:\")\n",
        "        for example in misclassified:\n",
        "            print(\"Input: \", decode_labels(example[0]))\n",
        "            print(\"Actual: \", example[1].strip())\n",
        "            print(\"Predicted: \", example[2].strip())\n",
        "            print(\"-\" * 30)\n",
        "\n",
        "    def build_image2text_model(input_shape, unique_characters, max_answer_length, learning_rate=0.001, dropout_rate=0.1):\n",
        "        image2text = models.Sequential()\n",
        "\n",
        "        image2text.add(layers.Reshape((input_shape[0], 28, 28, 1), input_shape=input_shape))        \n",
        "        # TimeDistributed Convolutional layers for feature extraction\n",
        "        image2text.add(layers.TimeDistributed(layers.Conv2D(32, (3, 3), activation='relu')))\n",
        "        image2text.add(layers.TimeDistributed(layers.MaxPooling2D((2, 2))))\n",
        "        image2text.add(layers.TimeDistributed(layers.Conv2D(64, (3, 3), activation='relu')))\n",
        "        image2text.add(layers.TimeDistributed(layers.MaxPooling2D((2, 2))))\n",
        "        image2text.add(layers.TimeDistributed(layers.Conv2D(64, (3, 3), activation='relu')))\n",
        "\n",
        "        # Flatten the output for the LSTM layers\n",
        "        image2text.add(layers.TimeDistributed(layers.Flatten()))\n",
        "\n",
        "        # LSTM layers for understanding the sequence\n",
        "        image2text.add(layers.LSTM(64, return_sequences=True))\n",
        "        image2text.add(layers.LSTM(64))\n",
        "\n",
        "        # Dense layers for interpretation and output\n",
        "        image2text.add(layers.Dense(64, activation='relu'))\n",
        "        image2text.add(layers.Dropout(dropout_rate))\n",
        "        image2text.add(layers.Dense(len(unique_characters) * max_answer_length, activation='softmax'))\n",
        "\n",
        "        # Reshape to match the output format\n",
        "        image2text.add(layers.Reshape((max_answer_length, len(unique_characters))))\n",
        "\n",
        "        # Define the optimizer with the desired learning rate\n",
        "        adam_optimizer = optimizers.Adam(learning_rate=learning_rate)\n",
        "\n",
        "        # Compile the model with the custom optimizer\n",
        "        image2text.compile(optimizer=adam_optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "        image2text.summary()\n",
        "        plot_model(image2text, to_file='./figures/model_image2text_54_plot.png', show_shapes=True, show_layer_names=True)\n",
        "\n",
        "        return image2text\n",
        "\n",
        "\n",
        "    def main(learning_rate, dropout_rate, epochs, test_size):\n",
        "\n",
        "        highest_integer = 99\n",
        "        max_answer_length = 4\n",
        "\n",
        "        epochs=epochs\n",
        "        dropout_rate=dropout_rate\n",
        "        learning_rate=learning_rate\n",
        "        patience_early_stopping=30\n",
        "        patience_learning_rate=10\n",
        "\n",
        "        # Generate the dataset\n",
        "        X_text, X_img, y_text, y_img = create_data(unique_characters, highest_integer, num_addends=2, operands='*')\n",
        "        X_text, X_img, y_text, y_img = shuffle(X_text, X_img, y_text, y_img, random_state=random_seed)\n",
        "\n",
        "        # Preprocess images for LSTM\n",
        "        X_img_preprocessed = X_img.reshape(X_img.shape[0], X_img.shape[1], 28, 28, 1)\n",
        "        y_text_onehot = encode_labels(y_text)  # Implement encode_labels accordingly\n",
        "\n",
        "        # Splitting the dataset\n",
        "        X_train, X_temp, y_train, y_temp = train_test_split(X_img_preprocessed, y_text_onehot, test_size=test_size, random_state=random_seed)\n",
        "        X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=test_size, random_state=random_seed)\n",
        "\n",
        "        # Building the model\n",
        "        model = build_image2text_model(X_train.shape[1:], unique_characters, max_answer_length, learning_rate, dropout_rate)\n",
        "\n",
        "        # Define callbacks\n",
        "        callbacks = [EarlyStopping(monitor='val_loss', patience=patience_early_stopping, verbose=1),\n",
        "                    ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=patience_learning_rate, min_lr=1.e-6, verbose=1),\n",
        "                    TensorBoard(log_dir=\"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"), histogram_freq=1)]\n",
        "\n",
        "        history=model.fit(X_train, y_train, epochs=epochs, batch_size=128, validation_data=(X_val, y_val), callbacks=callbacks)\n",
        "\n",
        "        test_loss, test_acc = model.evaluate(X_test, y_test)\n",
        "        print(f\"Test Accuracy: {test_acc}\")\n",
        "        np.save('./results/image2text_54_training_history.npy', history.history)\n",
        "        model.save('./models/image2text_54_model.h5')\n",
        "\n",
        "        return test_acc\n",
        "\n",
        "    if __name__ == \"__main__\":\n",
        "        epochs=1000 # epochs=500 is used in the report, level is increased to attempt better performance\n",
        "        learning_rate=1.e-4\n",
        "        dropout_rate=0.1 #dropout of 0.05 is shown in the report, level is increased to attempt to reduce overfitting\n",
        "        unique_characters = '0123456789* '\n",
        "        highest_integer = 99\n",
        "        \n",
        "        test_accuracies = []\n",
        "        test_sizes = np.arange(0.1, 0.2, 0.2)  \n",
        "        for test_size in test_sizes:\n",
        "            print(f\"test size {test_size:2.1f}\")\n",
        "            test_accuracy = main(learning_rate, dropout_rate, epochs, test_size)\n",
        "            test_accuracies.append(test_accuracy)\n",
        "\n",
        "        # Assuming test_sizes and test_accuracies are defined and contain your data\n",
        "        np.savez('./results/image2text_54_test_performance.npz', test_sizes=test_sizes, test_accuracies=test_accuracies)\n",
        "        print(\"Data saved successfully.\")\n",
        "\n",
        "        plt.plot(test_sizes, test_accuracies)\n",
        "        plt.scatter(test_sizes, test_accuracies, marker='*', s=50)\n",
        "\n",
        "        # Loop through each point to place a text label\n",
        "        for i, txt in enumerate(test_accuracies):\n",
        "            plt.text(test_sizes[i], test_accuracies[i] - 0.01, f'{txt:.2f}', ha='center', va='top')  \n",
        "\n",
        "        plt.xlabel('test_size t')\n",
        "        plt.ylabel('Test Accuracy')\n",
        "        plt.ylim([0, 1])\n",
        "        plt.title('image2text_54 model performance across test sizes')\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(f'./figures/experiment_6: image2text_54 accuracy across test sizes {epochs} {dropout_rate} {learning_rate}.pdf')\n",
        "    # experiment 3: t2t addition/substraction\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Apply what you learned in the previous tasks and try to tune the architecture/hyperparameters of\n",
        "# your models further. What is the highest accuracy on the test set that you can achieve and what kind\n",
        "# of train/test sample ratio can you use?\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "FZ7Xx__nJmj7"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "qsprpred",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
